<source>
  @type tail
  path "/var/log/containers/*.log"
  pos_file fluentd-docker.pos
  time_format %Y-%m-%dT%H:%M:%S
  tag kubernetes.*
  format json
  read_from_head true
</source>

<filter kubernetes.**>
  @type kubernetes_metadata
</filter>

<match kubernetes.**>
  @type rewrite_tag_filter
  <rule>
    key $['kubernetes']['labels']['app_kubernetes_io/managed-by']
    pattern /^.*tekton-pipelines.*$/
    tag tekton-pipelines.$['kubernetes']['labels']['tekton_dev/pipelineRun'].$['kubernetes']['labels']['tekton_dev/taskRun']
  </rule>
</match>

# <match tekton-pipelines>
#   @type stdout
# </match>

<match tekton-pipelines.**>
  @type s3
  aws_key_id admin123
  aws_sec_key admin123
  s3_endpoint http://9.21.53.162:31846/
  s3_bucket pipeline-logs
  s3_region test_region
  path ${$.kubernetes.labels.tekton_dev/pipelineRun}/${$.kubernetes.pod_name}/      # This prefix is added to each file
  force_path_style true         # This prevents AWS SDK from breaking endpoint URL
  time_slice_format %Y%m%d%H%M  # This timestamp is added to each file name
  <buffer time>
    @type file
    path /var/log/td-agent/s3
    timekey 120s                 # Flush the accumulated chunks every xx
    timekey_wait 60s             # Wait for xx seconds before flushing
    timekey_use_utc true        # Use this option if you prefer UTC timestamps
    chunk_limit_size 30m       # The maximum size of each chunk
  </buffer>
</match>
